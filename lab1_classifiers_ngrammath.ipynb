{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Classification! (and some n-gram math)\n",
    "\n",
    "#### Due on 02/02/2024 @ 21:00 hours\n",
    "\n",
    "Agenda\n",
    "------\n",
    "+ Detecting the end of a sentence\n",
    "    - Rule-based classifier\n",
    "+ Detecting the sentiment of a sentence\n",
    "    - Rule-based classifier (counting words)\n",
    "    - Measuring Accuracy, Precision, Recall (evaluating a classifier)\n",
    "+ N-gram Math (getting started on things for HW 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking ahead, we'll be focusing on *classification* for much of the next several weeks. Classification can take several forms. Here are some vocabulary terms to get you started:\n",
    "\n",
    "- __classifier__: a model that takes data (text, in NLP) as input and outputs a category\n",
    "- __binary classification__: a model that takes input and outputs *one of two* categories (e.g. \"positive\" or \"negative\")\n",
    "- __multinomial classification__: a model that takes input and outputs *one of many* categories (e.g. \"positive\", \"neutral\" or \"negative\" or a language model that chooses one token from the entire vocabulary)\n",
    "\n",
    "\n",
    "- __rule-based classifier__: a classifier that functions based on rules that humans come up with (e.g. \"the end of a sentence is when there is a \".\" \")\n",
    "- __statistical classifier__: a classifier that functions based on counts (statistics) that it has gathered or based on running an algorithm to automatically train parameters on a given data set. \n",
    "    \n",
    "In this lab, you'll be building rule-based classifiers and evaluating them. We'll learn about our first statistical classifier next lecture\n",
    "\n",
    "All tasks have equal weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0: Who is in your group?\n",
    "\n",
    "__WRITE YOUR NAMES HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Detecting the end of a sentence\n",
    "\n",
    "\n",
    "A classifier is, in essence, a function that takes some data $x$ and assigns some label $y$ to it. For a binary classifier, we can model this a function that takes a data point $x$ and returns either `True` or `False`.\n",
    "\n",
    "Later in this class we'll learn about how to build classifiers that automatically learn how to do this, but we'll start where NLP startedâ€”writing some rule-based classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence_end(text: str, target_index: int) -> bool: \n",
    "    \"\"\"\n",
    "    Classify whether or not a *location* is the end of a sentence within\n",
    "    a given text\n",
    "    Parameters:\n",
    "        text - string piece of text\n",
    "        target_index - int candidate location\n",
    "    returns true if the target index is the end of a sentence. \n",
    "    False otherwise. \n",
    "    \"\"\"\n",
    "    # TODO: write a simple, rule-based classifier that\n",
    "    # decides whether or not a specific location is the \n",
    "    # end of a sentence\n",
    "    pass \n",
    "\n",
    "# look at the code in the cell below to see example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text\n",
    "# feel free to go through different examples\n",
    "\n",
    "# This is the given example text\n",
    "\"\"\"Stocks were up as advancing issues outpaced declining issues \n",
    "          on the NYSE by 1.5 to 1. Large- and small-cap stocks were both strong, \n",
    "          while the S.&P. 500 index gained 0.46% to finish at 2,457.59. Among \n",
    "          individual stocks, the two top percentage gainers in the S.&P. 500 \n",
    "          were Incyte Corporation and Gilead Sciences Inc.\"\"\"\n",
    "\n",
    "example = \"Stocks were up as advancing issues outpaced declining issues on the NYSE by 1.5 to 1. Large- and small-cap stocks were both strong, while the S.&P. 500 index gained 0.46% to finish at 2,457.59. Among individual stocks, the two top percentage gainers in the S.&P. 500 were Incyte Corporation and Gilead Sciences Inc.\"\n",
    "\n",
    "# this code will go through and\n",
    "# build up a string based on the sentence\n",
    "# decisions that your classifier comes up with\n",
    "# it will put \"****\" between the sentences\n",
    "# you do not need to modify any code here\n",
    "so_far = \"\"\n",
    "for index in range(len(example)):\n",
    "    # see how the classify_sentence_end function is called!\n",
    "    result = classify_sentence_end(example, index)\n",
    "    so_far += example[index]\n",
    "    if result:\n",
    "        print(so_far)\n",
    "        print(\"****\")\n",
    "        so_far = \"\"\n",
    "        \n",
    "print(so_far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many sentences are detected using your end of sentence classifier? **YOUR ANSWER HERE**\n",
    "2. Where did your end of sentence classifier make a mistake? **YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Determining Sentiment\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use nltk to access the reviews that we want to classify eventually\n",
    "import nltk\n",
    "import nltk.corpus as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_list(filename):\n",
    "    \"\"\"\n",
    "    Loads a lexicon from a plain text file in the format of one word per line.\n",
    "    Parameters:\n",
    "    filename (str): path to file\n",
    "\n",
    "    Returns:\n",
    "    list: list of words\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "        # skip the header content\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                break\n",
    "        # read the rest of the lines into a list\n",
    "        return [line.strip() for line in f]\n",
    "    # otherwise return an empty list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the positive and negative word lists here\n",
    "# TODO: the paths to your negative/positive word files here\n",
    "neg_lex = load_word_list(\"NEGATIVE WORD LIST PATH\")\n",
    "pos_lex = load_word_list(\"POSITIVE WORD LIST PATH\")\n",
    "\n",
    "# TODO: How many words are in each list?\n",
    "\n",
    "\n",
    "# TODO: Use python's list slicing to look at the first 10 elements in each list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: which words are in both the positive and the negative lists?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create our rule-based classifier! We have access to the word lists that you loaded and anything else you know about the world (reflect on how you as a human being can tell if a review is positive/negative). Your classifier need not be perfect, but it should be reasonable (don't just say everything is positive!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_classify(tokens, pos_lexicon, neg_lexicon, verbose = False):\n",
    "    \"\"\"\n",
    "    This function classifies a given tokenized text as positive or negative\n",
    "    based on the provided lexicons.\n",
    "    Parameters:\n",
    "    tokens (list) - list of strings tokenized words in the text to classify\n",
    "    pos_lexicon (list) - list of strings words in the positive word lexicon\n",
    "    neg_lexicon (list) - list of strings words in the negative word lexicon\n",
    "    verbose (boolean) - flag indicating whether or not to print verbose (debugging) output. \n",
    "            Default value False.\n",
    "    Returns:\n",
    "    string \"pos\" if the list of tokens is positive overall, \"neg\" if they are negative overall.\n",
    "    \"\"\"\n",
    "    # TODO: implement this function! This is our classifier.  \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we'll test out your classifier!\n",
    "# Here are two example movie reviews.\n",
    "nltk.download('movie_reviews')\n",
    "movies = corpus.movie_reviews\n",
    "\n",
    "# load in a single negative review\n",
    "negative_toks = movies.words('neg/cv001_19502.txt')\n",
    "# uncomment the text below to see the contents of the review\n",
    "# neg_text = \" \".join(negative_toks)\n",
    "# print(neg_text)\n",
    "\n",
    "# load in a single positive review\n",
    "positive_toks = movies.words('pos/cv992_11962.txt')\n",
    "# pos_text = \" \".join(positive_toks)\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# call your rule_based_classify on these example reviews.\n",
    "\n",
    "# Does our classification function label them correctly? Why or why not?\n",
    "# take a look at the contents of the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What labels does your classifier assign these two reviews? __YOUR ANSWER HERE__\n",
    "2. Are these correct? __YOUR ANSWER HERE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: How good is your sentiment classifier?\n",
    "-----\n",
    "\n",
    "Given the movies dataset from `nltk`, how many of the reviews does your classifier classify correctly?\n",
    "\n",
    "We'll look at three different metrics: __accuracy__, __precision__, and __recall__.\n",
    "\n",
    "__accuracy__: what you think of when you think of correctness.\n",
    "$$ \\frac{\\texttt{number correct}}{\\texttt{total number}}$$\n",
    "\n",
    "Precision and recall require differentiated between the ways in which the classifier can be correct or incorrect. \n",
    "\n",
    "- __true positive__: an example whose gold label is positive and that the classifier labels as positive\n",
    "- __true negative__: an example whose gold label is negative and that the classifier labels as negative\n",
    "- __false positive__: an example whose gold label is negative and that the classifier labels as positive\n",
    "- __false negative__: an example whose gold label is positive and that the classifier labels as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# you can use numpy's random functionality if you'd like to\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the available file ids, this is one way that we can access them.\n",
    "# This will give you a list of neg/positive file ids.\n",
    "print(len(movies.fileids('neg')))\n",
    "# choose 100 random items without replacement from a list\n",
    "print(random.sample(movies.fileids('neg'), 100))\n",
    "print(len(movies.fileids('pos')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Write code that uses your classifier to classify 100 randomly chosen\n",
    "# negative reviews and 100 randomly chosen positive reviews\n",
    "# count the number of true positives, true negatives, false positives, and false negatives\n",
    "\n",
    "# to get the tokens associated with a certain file id,\n",
    "# tokens = movies.words(file_id)\n",
    "\n",
    "# takes a long time to run if you loop over all fileids as opposed to just\n",
    "# 100 randomly chosen ones\n",
    "# make sure you don't classify the same review twice!\n",
    "# (it takes us about 10 seconds to classify 200 reviews on a 2020 macbook air)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# TODO: print out the number of true positives, false positives,\n",
    "# false negatives, and true negatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the equations for accuracy, precision, and recall in terms of what we've just been counting. $tp$ means true positive, $fp$ means false positive, $fn$ means false negative, and $tn$ means true negative.\n",
    "\n",
    "$$ accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$$\n",
    "\n",
    "$$ precision = \\frac{tp}{tp + fp}$$\n",
    "\n",
    "$$ recall = \\frac{tp}{tp + fn}$$\n",
    "\n",
    "You can think of precision as \"how many of my positive guesses were correct?\" and recall as \"how many of the positive examples did I find?\" ðŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate and print accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate and print precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate and print recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: n-gram math\n",
    "----\n",
    "\n",
    "Your final task in this lab is to do some math that will help you with your n-gram language model homework. Remember in HW 1 how you implemented a `count_list` function? Some of you were clever with how you implemented it, but let's look at a less clever implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "def count_list(ls: list) -> dict:\n",
    "    counts = {}\n",
    "    for item in ls:\n",
    "        # we're not going to be clever about counting here,\n",
    "        # no conditionals, no sets, nothing\n",
    "        counts[item] = ls.count(item)\n",
    "    return counts\n",
    "\n",
    "# see the difference between the following two items\n",
    "example = [random.randint(0, 100) for i in range(2000)]\n",
    "start = time.time()\n",
    "count_list(example)\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds!\")\n",
    "\n",
    "# this takes a very similar amount of time to count_dict from HW 1\n",
    "start = time.time()\n",
    "Counter(example)\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put your create_ngrams (or make_ngrams) function here!\n",
    "def make_ngrams(tokens: list, n: int) -> list:\n",
    "    \"\"\"Creates n-grams for the given token sequence.\n",
    "    Args:\n",
    "    tokens (list): a list of tokens as strings\n",
    "    n (int): the length of n-grams to create\n",
    "\n",
    "    Returns:\n",
    "    list: list of tuples of strings, each tuple being one of the individual n-grams\n",
    "    \"\"\"\n",
    "    # TODO: implement this function!\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the bigram score of the following sequence of tokens\n",
    "# for this example, we'll use a \"vanilla\" scoring technique\n",
    "# no Laplace smoothing, no unknown tokens\n",
    "training_data = [\"<s>\", \"I\", \"love\", \"dogs\", \"</s>\", \"<s>\", \"I\", \"love\", \"cats\", \"</s>\", \"<s>\", \"I\", \"love\", \"dinosaurs\", \"</s>\"]\n",
    "\n",
    "# TODO: call your create_ngrams function to get your bigrams\n",
    "\n",
    "\n",
    "\n",
    "to_score = [\"<s>\", \"I\", \"love\", \"cats\", \"</s>\"]\n",
    "start = time.time()\n",
    "\n",
    "# BEGIN SCORING SECTION\n",
    "# start probability at one so that we can multiply the probability of\n",
    "# each subsequent next token with it\n",
    "total_prob = 1\n",
    "for i in range(1, len(to_score)):\n",
    "    # TODO: YOUR SCORE CALCULATION CODE HERE\n",
    "    \n",
    "\n",
    "# END SCORING SECTION\n",
    "end = time.time()\n",
    "\n",
    "# print your final probability\n",
    "print(\"Final probability:\", total_prob)\n",
    "print(\"That took\", end - start, \"seconds!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, pretend that we had a lot more data\n",
    "training_data = [\"<s>\", \"I\", \"love\", \"dogs\", \"</s>\", \"<s>\", \"I\", \"love\", \"cats\", \"</s>\", \"<s>\", \"I\", \"love\", \"dinosaurs\", \"</s>\"]\n",
    "# this is the amount of training data in the berp set\n",
    "training_data = training_data * 3778\n",
    "\n",
    "# TODO: call your create_ngrams function here\n",
    "\n",
    "\n",
    "print(\"Number of training tokens:\", len(training_data))\n",
    "start = time.time()\n",
    "# and what if we had 5000 sentences to score?\n",
    "for example_num in range(3000):\n",
    "    # TODO: COPY AND PASTE YOUR SCORING CODE HERE (between \"BEGIN SCORING SECTION\" and \"END SCORING SECTION\")\n",
    "    # (remove any print statements that you have)\n",
    "    # (make sure it is appropriately indented)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(\"That took\", end - start, \"seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the moral of the story? If you perform your counts at the same time you score, you'll be doing the same work over and over again which will result in a significantly slower model!\n",
    "\n",
    "Make sure that you're gathering the counts that you need in `train` and only performing scoring calculations (as opposed to also counting things) in `score`.\n",
    "\n",
    "This is particularly important when using larger data sets! (berp is not that big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
